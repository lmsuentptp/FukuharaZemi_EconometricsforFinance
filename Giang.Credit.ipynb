{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2b6abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38      2486\n",
      "           1       0.76      0.92      0.84      6186\n",
      "\n",
      "    accuracy                           0.74      8672\n",
      "   macro avg       0.68      0.60      0.61      8672\n",
      "weighted avg       0.72      0.74      0.71      8672\n",
      "\n",
      "[[ 697 1789]\n",
      " [ 467 5719]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538224\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          DefaulterFlag   No. Observations:                20234\n",
      "Model:                          Logit   Df Residuals:                    20220\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Fri, 26 Jan 2024   Pseudo R-squ.:                  0.1047\n",
      "Time:                        14:11:55   Log-Likelihood:                -10890.\n",
      "converged:                       True   LL-Null:                       -12163.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4454      0.137     10.562      0.000       1.177       1.714\n",
      "AGE           -0.0149      0.002     -8.708      0.000      -0.018      -0.012\n",
      "NOOFDEPE       0.0462      0.011      4.257      0.000       0.025       0.067\n",
      "MTHINCTH      -0.0008      0.004     -0.230      0.818      -0.008       0.006\n",
      "SALDATFR      -0.4659      0.042    -11.222      0.000      -0.547      -0.385\n",
      "TENORYR        0.7081      0.045     15.754      0.000       0.620       0.796\n",
      "DWNPMFR       -1.0582      0.129     -8.176      0.000      -1.312      -0.805\n",
      "PROFBUS        0.2728      0.049      5.538      0.000       0.176       0.369\n",
      "QUALHSC        0.1349      0.041      3.305      0.001       0.055       0.215\n",
      "QUAL_PG       -0.3240      0.081     -4.007      0.000      -0.482      -0.166\n",
      "SEXCODE        0.2752      0.061      4.510      0.000       0.156       0.395\n",
      "FULLPDC       -1.2724      0.035    -36.107      0.000      -1.341      -1.203\n",
      "FRICODE       -0.1908      0.039     -4.932      0.000      -0.267      -0.115\n",
      "WASHCODE      -0.1671      0.046     -3.633      0.000      -0.257      -0.077\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HHGiang\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file_path = 'C:/Users/HHGiang/Documents/KEIO/3FZ/IMB469-XLS-ENG.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Define the predictor variables (excluding 'Agmt No' and 'Start_Date') and the target variable\n",
    "predictor_columns = [\n",
    "    'AGE', 'NOOFDEPE', 'MTHINCTH', 'SALDATFR', 'TENORYR', 'DWNPMFR',\n",
    "    'PROFBUS', 'QUALHSC', 'QUAL_PG', 'SEXCODE', 'FULLPDC', 'FRICODE', 'WASHCODE'\n",
    "]\n",
    "X = data[predictor_columns]\n",
    "y = data['DefaulterFlag']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a logistic regression model instance\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the test data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Fit a logistic regression model using statsmodels for detailed summary\n",
    "X_train_sm = sm.add_constant(X_train)  # Adding a constant for the intercept\n",
    "logit_model = sm.Logit(y_train, X_train_sm).fit()\n",
    "\n",
    "# Print the summary of the logistic regression model\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d2625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38      2486\n",
      "           1       0.76      0.92      0.84      6186\n",
      "\n",
      "    accuracy                           0.74      8672\n",
      "   macro avg       0.68      0.60      0.61      8672\n",
      "weighted avg       0.72      0.74      0.71      8672\n",
      "\n",
      "[[ 703 1783]\n",
      " [ 470 5716]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538225\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          DefaulterFlag   No. Observations:                20234\n",
      "Model:                          Logit   Df Residuals:                    20221\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Fri, 26 Jan 2024   Pseudo R-squ.:                  0.1047\n",
      "Time:                        14:16:16   Log-Likelihood:                -10890.\n",
      "converged:                       True   LL-Null:                       -12163.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4366      0.131     10.936      0.000       1.179       1.694\n",
      "AGE           -0.0149      0.002     -8.770      0.000      -0.018      -0.012\n",
      "NOOFDEPE       0.0462      0.011      4.257      0.000       0.025       0.067\n",
      "SALDATFR      -0.4643      0.041    -11.340      0.000      -0.545      -0.384\n",
      "TENORYR        0.7092      0.045     15.858      0.000       0.622       0.797\n",
      "DWNPMFR       -1.0552      0.129     -8.194      0.000      -1.308      -0.803\n",
      "PROFBUS        0.2719      0.049      5.537      0.000       0.176       0.368\n",
      "QUALHSC        0.1358      0.041      3.342      0.001       0.056       0.215\n",
      "QUAL_PG       -0.3250      0.081     -4.025      0.000      -0.483      -0.167\n",
      "SEXCODE        0.2756      0.061      4.518      0.000       0.156       0.395\n",
      "FULLPDC       -1.2733      0.035    -36.349      0.000      -1.342      -1.205\n",
      "FRICODE       -0.1920      0.038     -5.011      0.000      -0.267      -0.117\n",
      "WASHCODE      -0.1673      0.046     -3.636      0.000      -0.257      -0.077\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HHGiang\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file_path = 'C:/Users/HHGiang/Documents/KEIO/3FZ/IMB469-XLS-ENG.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Define the predictor variables (excluding 'Agmt No' and 'Start_Date') and the target variable\n",
    "predictor_columns = [\n",
    "    'AGE', 'NOOFDEPE', 'SALDATFR', 'TENORYR', 'DWNPMFR',\n",
    "    'PROFBUS', 'QUALHSC', 'QUAL_PG', 'SEXCODE', 'FULLPDC', 'FRICODE', 'WASHCODE'\n",
    "]\n",
    "X = data[predictor_columns]\n",
    "y = data['DefaulterFlag']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a logistic regression model instance\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the test data\n",
    "predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Fit a logistic regression model using statsmodels for detailed summary\n",
    "X_train_sm = sm.add_constant(X_train)  # Adding a constant for the intercept\n",
    "logit_model = sm.Logit(y_train, X_train_sm).fit()\n",
    "\n",
    "# Print the summary of the logistic regression model\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6211b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536849\n",
      "         Iterations 6\n",
      "Cutoff probabilities for various LGDs:\n",
      "{1.0: 0.2042979440918913, 0.5: 0.33724589204264893, 0.2: 0.5598741557175612}\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_excel(\"C:\\\\Users\\\\HHGiang\\\\Documents\\\\KEIO\\\\3FZ\\\\IMB469-XLS-ENG.xlsx\")\n",
    "\n",
    "# Define your features and target variable based on the data\n",
    "features = ['AGE', 'NOOFDEPE', 'SALDATFR', 'TENORYR', 'DWNPMFR', 'PROFBUS', 'QUALHSC', 'QUAL_PG', 'SEXCODE', 'FULLPDC', 'FRICODE', 'WASHCODE']\n",
    "target = 'DefaulterFlag'\n",
    "\n",
    "# Prepare the features by adding a constant term for the intercept\n",
    "X = sm.add_constant(data[features])\n",
    "y = data[target]\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Predict the probability of default\n",
    "data['prob_default'] = logit_model.predict(X)\n",
    "\n",
    "# Define the function to calculate the expected profit and loss\n",
    "def calculate_nev(principal, interest_rate, term, prob_default, lgd):\n",
    "    expected_profit = principal * ((1 + interest_rate) ** term) - principal\n",
    "    expected_loss = principal * lgd\n",
    "    nev = (1 - prob_default) * expected_profit - prob_default * expected_loss\n",
    "    return nev\n",
    "\n",
    "# Constants\n",
    "interest_rate = 0.12\n",
    "loan_term = 2\n",
    "loan_principal = 10000  # Example principal amount\n",
    "\n",
    "# Calculate NEV for various LGD scenarios\n",
    "lgds = [1.0, 0.5, 0.2]  # Example LGDs\n",
    "for lgd in lgds:\n",
    "    data[f'nev_lgd_{lgd}'] = data['prob_default'].apply(lambda p: calculate_nev(loan_principal, interest_rate, loan_term, p, lgd))\n",
    "\n",
    "# Determine the cutoff probability for each LGD scenario\n",
    "cutoffs = {}\n",
    "for lgd in lgds:\n",
    "    # Sort the data by probability of default and reset the index\n",
    "    sorted_data = data.sort_values(by='prob_default').reset_index()\n",
    "    # Find the first negative NEV\n",
    "    cutoff_index = sorted_data[sorted_data[f'nev_lgd_{lgd}'] < 0].index[0]\n",
    "    # The corresponding probability of default is the cutoff\n",
    "    cutoffs[lgd] = sorted_data.loc[cutoff_index, 'prob_default']\n",
    "\n",
    "# Print the cutoff probabilities\n",
    "print(\"Cutoff probabilities for various LGDs:\")\n",
    "print(cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f692af31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537433\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:           CustomerType   No. Observations:                23124\n",
      "Model:                        MNLogit   Df Residuals:                    23110\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Fri, 26 Jan 2024   Pseudo R-squ.:                  0.1072\n",
      "Time:                        14:47:30   Log-Likelihood:                -12428.\n",
      "converged:                       True   LL-Null:                       -13920.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "CustomerType=Marginal       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     1.0351      0.016     63.364      0.000       1.003       1.067\n",
      "x1                       -0.1527      0.016     -9.692      0.000      -0.184      -0.122\n",
      "x2                        0.0729      0.016      4.442      0.000       0.041       0.105\n",
      "x3                       -0.0164      0.016     -0.997      0.319      -0.049       0.016\n",
      "x4                       -0.2027      0.018    -11.300      0.000      -0.238      -0.168\n",
      "x5                        0.3600      0.022     16.440      0.000       0.317       0.403\n",
      "x6                       -0.1851      0.019     -9.774      0.000      -0.222      -0.148\n",
      "x7                        0.0852      0.016      5.243      0.000       0.053       0.117\n",
      "x8                        0.0472      0.016      2.937      0.003       0.016       0.079\n",
      "x9                       -0.0689      0.015     -4.658      0.000      -0.098      -0.040\n",
      "x10                       0.0744      0.015      4.890      0.000       0.045       0.104\n",
      "x11                      -0.6251      0.016    -38.839      0.000      -0.657      -0.594\n",
      "x12                      -0.0926      0.018     -5.187      0.000      -0.128      -0.058\n",
      "x13                      -0.0652      0.017     -3.866      0.000      -0.098      -0.032\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the data from the Excel file\n",
    "data = pd.read_excel(r\"C:\\Users\\HHGiang\\Documents\\KEIO\\3FZ\\IMB469-XLS-ENG.xlsx\")\n",
    "\n",
    "# Define the target variable \"CustomerType\" based on your criteria\n",
    "data['CustomerType'] = 'Good'\n",
    "data.loc[data['DefaulterFlag'] == 1, 'CustomerType'] = 'Marginal'\n",
    "data.loc[data['DefaulterFlag'] > 1, 'CustomerType'] = 'Poor'\n",
    "# Define predictor variables (exclude irrelevant columns)\n",
    "X = data[['AGE', 'NOOFDEPE', 'MTHINCTH', 'SALDATFR', 'TENORYR', 'DWNPMFR', 'PROFBUS', 'QUALHSC', 'QUAL_PG', 'SEXCODE', 'FULLPDC', 'FRICODE', 'WASHCODE']]\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, data['CustomerType'], test_size=0.2, random_state=42)\n",
    "# Add a constant term to the predictor variables\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the multinomial logistic regression model\n",
    "model = sm.MNLogit(y_train, X_train).fit()\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534a223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
